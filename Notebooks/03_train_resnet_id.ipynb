{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c28994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cpu\n",
      "Epoch [1/5], Loss: 8.5462\n",
      "Epoch [2/5], Loss: 3.7063\n",
      "Epoch [3/5], Loss: 1.7012\n",
      "Epoch [4/5], Loss: 0.9839\n",
      "Epoch [5/5], Loss: 0.6665\n",
      " Model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device in use:\", device)\n",
    "\n",
    "# Paths\n",
    "id_path = r\"D:\\ODD PROJECT\\DATA\\BDD\\scene_classification\\ID\"\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet standards\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset (we treat all as one class here)\n",
    "dataset = datasets.ImageFolder(root=r\"D:\\ODD PROJECT\\DATA\\BDD\\scene_classification\", transform=transform)\n",
    "\n",
    "# Create labels manually: 0 for ID, 1 for OOD (weâ€™ll use OOD later)\n",
    "# For now: just train on class 0 (id)\n",
    "id_only = [img for img in dataset.samples if \"id\" in img[0].lower()]\n",
    "dataset.samples = id_only\n",
    "\n",
    "# Dataloader\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Load pretrained ResNet-18\n",
    "# Load ResNet-18 without weights (base model)\n",
    "model = resnet18()\n",
    "\n",
    "# Load manually downloaded weights\n",
    "model.load_state_dict(torch.load(r\"D:\\ODD PROJECT\\weights\\resnet18-f37072fd.pth\"))\n",
    "\n",
    "# Modify the final layer\n",
    "import torch.nn as nn\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for imgs, _ in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = torch.zeros(imgs.size(0), 1).to(device)  # All labels are 0 (ID)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../models/resnet18_id_only.pth\")\n",
    "print(\" Model trained and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
